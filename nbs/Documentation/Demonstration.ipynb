{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstratation of TinyMLaaS WebApp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This document will demonstrate the steps in TinyMLaaS app. Some pages have dependencies on other pages, so go through pages from top to bottom is recommended at the start.\n",
    "\n",
    "In order to run TinyMLaaS end-to-end following components need to be run:\n",
    "- The Frontend\n",
    "- The Backend\n",
    "- The Relay\n",
    "\n",
    "These can all easily be started with the help of docker using the [docker-compose-with-bridge.yml](https://github.com/TinyMLaas/TinyMLaaS/blob/main/docker-compose-with-bridge.yml) file in the [Main repository](https://github.com/TinyMLaas/TinyMLaaS). The application can be started with\n",
    "\n",
    "```bash\n",
    "docker compose up -f docker-compose-with-brdige.yml -d\n",
    "```\n",
    "\n",
    "## Device\n",
    "\n",
    "In order to install a model to a embedded device, the briging device of the wanted device and the device need to be selected.\n",
    "\n",
    "The first thing that should be done on the *Device* page is to either add a new bridge or selecting an existing bridge. Let's add the bridge that was started by docker compose. To do that, add the name of the bridge docker container with the port 8080 as the bridges address. The bridge will also not use a HTTPS connection in this case.\n",
    "\n",
    "![Add new bridge](images/add_new_bridge.png)\n",
    "\n",
    "After adding the bridge, select the wanted bridge by clicking the *Select bridge* button next to the wanted bridge\n",
    "\n",
    "![Select the bridge](images/select_bridge.png)\n",
    "\n",
    "Selecting a device to which to install the trained machine learning model later on is required. If the wanted device has not been registered already, register it either manually or by selecting it from the list of devices connected to the bridge. Lets add a device connected to the bridge by pressing the *Register this device* button next to that device\n",
    "\n",
    "![Register the new device](images/show_connected_devices.png)\n",
    "\n",
    "Add the missing information on the form and click *add*\n",
    "\n",
    "![Device form](images/device_form.png)\n",
    "\n",
    "The added device will automatically be selected as the active device.\n",
    "\n",
    "![Selected device](images/device_selected.png)\n",
    "\n",
    "[//]: # (Tästä eteenpäin on vielä väärää tietoa)\n",
    "## Data\n",
    "\n",
    "First, select a dataset used for training of the model. \n",
    "\n",
    "![Dataset upload finalized](images/dataset_ready.png)\n",
    "\n",
    "Extracting images from archived file with localstack should take about 1-3min. This time should be reduced greatly when the datasets are actually stored in S3. After the app has confirmed the dataset has been uploaded, user is able to view images included the dataset. \n",
    "\n",
    "User can add images from local storage to selected dataset and label those. If the uploaded images are unlabeled they are not used for training in later stage of the process. However user can label those later if needed. \n",
    "\n",
    "Note that if you upload many images, streamlit's performance might reduce. Also, images added to dataset is available only for this session, the app doesn't support saving new images to datasets permanently. \n",
    "\n",
    "## Model\n",
    "\n",
    "For now the app supports only one model and therefore, this tab has been filled with dummy data. Changing selections on this tab doesn't impact to the model. \n",
    "\n",
    "To continue press Select button.\n",
    "\n",
    "## Training\n",
    "\n",
    "Before training the Keras model, model training settings need to be defined. A user need to enter information regarding number of epocs, batch size, image width and image height. The current model can be only trained if image width and image height are same and if loss function is Sparse Categorical.\n",
    "\n",
    "Here are example inputs for training a model.\n",
    "\n",
    "![Training input settings](images/training_settings.png)\n",
    "\n",
    "Press Train to continue.\n",
    "\n",
    "## Compiling\n",
    "\n",
    "The page is responsible for ML compilation. This page is also filled with dummy data, so selections won't impact on compiling result. \n",
    "\n",
    "Press Compile to continue.\n",
    "\n",
    "## Installing\n",
    "\n",
    "On the installing sheet, user must select a model and a device. Like stated before, app supports one model and two devices.\n",
    "\n",
    "The user must have plugged the device into the USB-port before building the docker image. It is good to check that the device is plugged into correct port, since plugging into incorrect port creates an error. If build time seems to be unexpectedly long, it might be good idea to check there is no 'No device found on ttyACM0' warning when running the relay server. That means the commands used to communicate with a device require sudo rights. This can be easily fixed by altering device commands in the relay/main.py module.\n",
    "\n",
    "![Real-time predictions as device output](images/sudo.png)\n",
    "\n",
    "The building time varies depending on the device. The Arduino nano 33 BLE takes about 10-15min and Pico 5-10min to install. After building, a model is ready to be sent to the device.\n",
    "\n",
    "\n",
    "![Real-time predictions as device output](images/installation.png)\n",
    "\n",
    "To continue, user must first press Generate button (builds the docker image and upload it to dockerhub) and when that has been finalized user press Install button (installs the model on to the device using the docker image downloaded from dockerhub). If user wants to change the device, whole page needs to be rerun with new device.\n",
    "\n",
    "## Observing\n",
    "\n",
    "On the observing page, user can see real-time predictions from device when the start button has been activated. A plugged device sends approximately every second a prediction. Notice that with current model and camera the predictions are not very accurate. User can end printing new predictions to the app by pressing stop button.\n",
    "\n",
    "![Real-time predictions as device output](images/observing.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtualenv-MAIN",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
